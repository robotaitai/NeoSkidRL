# Recommended reward configuration for better learning
# Based on RL navigation best practices

env:
  seed: 0
  dt: 0.02
  episode_sec: 10.0
  frame_skip: 1

robot:
  length_m: 0.307
  width_m: 0.247
  wheel_diameter_m: 0.097
  wheel_radius_m: 0.0485
  wheelbase_m: 0.210
  track_m: 0.202

  drive:
    mode: "skid_steer"
    wheel_count: 4
    enforce_no_side_slip: true
    lateral_damping: 0.90

limits:
  v_max: 1.0
  w_max: 2.0
  wheel_vel_max: 30.0

control:
  action_space: "v_w"
  rate_limit:
    enabled: true
    max_delta_per_step: 0.20

sensors:
  lidar:
    enabled: true
    rays: 360
    range_m: 10.0
  cameras:
    render_camera: "track"
    rgb:
      enabled: true
      width: 320
      height: 240
      fov_deg: 90
    depth:
      enabled: true
      width: 320
      height: 240
      fov_deg: 90

world:
  arena_m: [6.0, 6.0]
  goal:
    fixed: true
    pos_m: [2.0, 0.0]
    yaw_deg: 0.0
    clearance_m: 0.60
    height_m: 0.01
  obstacles:
    max_count: 60
    count_range: [20, 40]
    size_xy_range_m: [0.30, 1.20]
    height_m: 0.40
    cylinder_prob: 0.40
    margin_m: 0.25

task:
  success:
    pos_tol_m: 0.30               # Relaxed from 0.20 for easier early success
    yaw_tol_deg: 30.0             # Relaxed from 10.0 (too strict!)
    stop_speed_mps: 0.15          # Slightly relaxed
  failure:
    collision: true
    stuck_sec: 1.5
    min_progress_m: 0.05

# RECOMMENDED WEIGHTS for "get it to learn" phase
reward:
  enabled_terms: ["progress", "heading", "velocity", "near_goal_speed", "time", "collision", "goal_bonus", "stuck"]  # Disable smooth and clearance initially
  weights:
    # Dense signal: Make progress the main driver
    progress: 15.0                # Even stronger positive for moving toward goal
    heading: 2.0                  # Small shaping for turning toward the goal
    velocity: 0.4                # Encourage moving toward the goal when far
    near_goal_speed: -1.0        # Discourage coasting near the goal
    
    # Sparse rewards/penalties
    goal_bonus: 100.0             # VERY BIG sparse reward for success
    collision: -50.0              # Moderate collision penalty (not too scary)
    stuck: -20.0                  # Penalty for getting stuck
    
    # Shaping rewards (DISABLED initially - enable after first successes)
    clearance: 0.0                # DISABLED - was causing robot to freeze
    smooth: 0.0                   # DISABLED - not needed for learning
    time: -0.005                  # Very tiny time penalty

  velocity_dslow_m: 1.0

# Notes:
# - Progress is 15 (main learning signal - VERY STRONG)
# - Heading is 2 (small shaping to allow turning toward goal)
# - Goal bonus is 100 (was 20) - makes agent REALLY care about success
# - Collision is -50 (was -10) - moderate penalty (not too scary)
# - Stuck penalty -20 to prevent freezing
# - Clearance DISABLED (0.0) - was causing robot to freeze!
# - Smoothness DISABLED (0.0) - not needed for initial learning
# - Time penalty very tiny (-0.005) so it doesn't drown learning
#
# Robot should now MOVE and try to reach goal!
#
# After you see consistent successes (>30%), you can:
# - Enable clearance: -0.3 (start small)
# - Enable smooth: -0.05 (for polish)
# - Reduce goal_bonus to 50-60
# - Increase collision to -75
# - Tighten success tolerances
